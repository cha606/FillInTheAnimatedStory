{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import mynn\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib notebook\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "L = 100\n",
    "W = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CleanData(x):\n",
    "    '''\n",
    "    Cleans the picture data so that it is compatable with the model\n",
    "    It forces the picture to have 3 dimensions, the last two are padded or cut to [X,1024,1024]\n",
    "    It turns a gray scale into a colored image\n",
    "    \n",
    "    Parameter\n",
    "    ---------\n",
    "    X is a numpy array [3,L,W] or [1,L,W]\n",
    "    \n",
    "    Output\n",
    "    ---------\n",
    "    Y a numpy array [3, 1024, 1024]\n",
    "    3 represents the RGB value\n",
    "    1024 represents the length of the picture\n",
    "    768 represents the width of the picture\n",
    "    '''\n",
    "    assert isinstance(x, np.ndarray) , \"You need your picture data to be a numpy array\"\n",
    "    assert len(x.shape)==3, \"Your picture data is messed up for some reason there are a different number of dimensions\"\n",
    "    #C/H/L\n",
    "    if x.shape == (3,1024,1024):#CHANGE\n",
    "        #Your data fits the requirements\n",
    "        return x    \n",
    "    if x.shape[1]<1024:\n",
    "        dummy = np.zeros((x.shape[0],1024,x.shape[2]))\n",
    "        dummy[:x.shape[0],:x.shape[1],:x.shape[2]] = x\n",
    "        x = dummy\n",
    "    if x.shape[2]<1024:\n",
    "        dummy = np.zeros((x.shape[0],x.shape[1],1024))\n",
    "        dummy[:x.shape[0],:x.shape[1],:x.shape[2]] = x\n",
    "        x = dummy\n",
    "    if x.shape[0]<3: #Meaning this is a noncolored image\n",
    "        print (f\"The original color channel was{x.shape[0]}\")\n",
    "        dummy = np.zeroes((3,x.shape[1],x.shape[2]))\n",
    "        dummy[:x.shape[0],:x.shape[1],:x.shape[2]] = x\n",
    "        x = dummy\n",
    "        \n",
    "    \n",
    "    \n",
    "    if x.shape[1]>1024 or x.shape[2] >1024: #Cut off function\n",
    "        x = x[:x.shape[0],:1024,:1024]\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    #if x.shape[1]<1024: #length\n",
    "     #   x1 = 1024 - x.shape[1]\n",
    "      #  add= np.zeros((3,x1,x.shape[2]))\n",
    "       # x= np.vstack((x,add))\n",
    "    #if x.shape[2]<1024: #width\n",
    "     #   x2 = 1024- x.shape[2]\n",
    "      #  add = np.zeros((3,x.shape[1],x2))\n",
    "        #x= np.hstack((x,add))\n",
    "    \n",
    "    assert x.shape == (3,1024,1024), \"For some reason your data cant be cleaned\"\n",
    "    print(f\"Your shape is {x.shape}\")\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CleanData2(x):\n",
    "    '''\n",
    "    Cleans the picture data so that it is compatable with the model\n",
    "    It forces the picture to have 3 dimensions, the last two are padded or cut to [X,1024,1024]\n",
    "    It turns a gray scale into a colored image\n",
    "    \n",
    "    Parameter\n",
    "    ---------\n",
    "    X is a numpy array [3,L,W] or [1,L,W]\n",
    "    \n",
    "    Output\n",
    "    ---------\n",
    "    Y a numpy array [3, 1024, 1024]\n",
    "    3 represents the RGB value\n",
    "    1024 represents the length of the picture\n",
    "    768 represents the width of the picture\n",
    "    \n",
    "    IMPORTANT this was just a quick test for optimization\n",
    "    \n",
    "    '''\n",
    "    assert isinstance(x, np.ndarray) , \"You need your picture data to be a numpy array\"\n",
    "    assert len(x.shape)==3, \"Your picture data is messed up for some reason there are a different number of dimensions\"\n",
    "    #C/H/L\n",
    "    dummy = np.zeros((3,1024,1024))\n",
    "    dummy[:3,:1024,:1024] = x\n",
    "    return dummy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3144704 3144705 3144706 ... 3145725 3145726 3145727]\n"
     ]
    }
   ],
   "source": [
    "#TEST CELL\n",
    "\n",
    "\n",
    "\n",
    "#x= np.array(([1,2,3],[1,2,3]))\n",
    "x = np.arange(3*1024*1024)\n",
    "x=np.reshape(x,[3,1024,1024])\n",
    "x= CleanData(x)\n",
    "print(x[2,1023])\n",
    "\n",
    "#print((np.pad(x,2,mode='constant')).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1024, 1024, 3)\n",
      "[[[      0       1       2 ...    1021    1022    1023]\n",
      "  [   1024    1025    1026 ...    2045    2046    2047]\n",
      "  [   2048    2049    2050 ...    3069    3070    3071]\n",
      "  ...\n",
      "  [1045504 1045505 1045506 ... 1046525 1046526 1046527]\n",
      "  [1046528 1046529 1046530 ... 1047549 1047550 1047551]\n",
      "  [1047552 1047553 1047554 ... 1048573 1048574 1048575]]\n",
      "\n",
      " [[1048576 1048577 1048578 ... 1049597 1049598 1049599]\n",
      "  [1049600 1049601 1049602 ... 1050621 1050622 1050623]\n",
      "  [1050624 1050625 1050626 ... 1051645 1051646 1051647]\n",
      "  ...\n",
      "  [2094080 2094081 2094082 ... 2095101 2095102 2095103]\n",
      "  [2095104 2095105 2095106 ... 2096125 2096126 2096127]\n",
      "  [2096128 2096129 2096130 ... 2097149 2097150 2097151]]\n",
      "\n",
      " [[2097152 2097153 2097154 ... 2098173 2098174 2098175]\n",
      "  [2098176 2098177 2098178 ... 2099197 2099198 2099199]\n",
      "  [2099200 2099201 2099202 ... 2100221 2100222 2100223]\n",
      "  ...\n",
      "  [3142656 3142657 3142658 ... 3143677 3143678 3143679]\n",
      "  [3143680 3143681 3143682 ... 3144701 3144702 3144703]\n",
      "  [3144704 3144705 3144706 ... 3145725 3145726 3145727]]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "print(x.transpose((1,2, 0)).shape)\n",
    "imgplot = plt.imshow(x.transpose((1,2, 0)))\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#What is the size?\n",
    "#AFTER IMPORT\n",
    "#data = \n",
    "#print(f\"image size {data.size} \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ConvertImtoNdArray (image):\n",
    "    return image.flatten().astype(np.float32)-np.mean(image)/np.std(image)\n",
    "#we want to flatten the array so that we can have one input layer. Subtracting by the mean then dividing by the std makes it normalized. The float is for precision by we dont want to much precision, so 32 is used.\n",
    "# Sould be uppercase pi (index)\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mynn.activations.relu import relu\n",
    "from mynn.initializers.glorot_uniform import glorot_uniform\n",
    "from mynn.layers.dense import dense\n",
    "from mynn.layers.conv import conv\n",
    "from mynn.layers.dropout import dropout\n",
    "\n",
    "class ModelT:\n",
    "    \n",
    "    def __init__(self):\n",
    "        '''The initial state of the model\n",
    "        '''\n",
    "        init_kwargs = {'gain': np.sqrt(2)} #MIGHT CHANGE\n",
    "        \n",
    "        \n",
    "        #As a reminder conv = conv(Input as in color channels, Psuedo Output, Fliter length, Filter width, Stride =1)\n",
    "        #conv2 = conv(Psuedo Output/Input, )\n",
    "        #If we input an array with Pic L, Pic W, 1(channel) then if our first conv has filters of length 5 our new array is (Pic L - Fil L +1, Pic W - Fil W +1, 1) \n",
    "        #Max Pooling divides Pic L and Pic W by 2\n",
    "        \n",
    "        self.conv1 = conv(3, 21, 513, 256, stride=(1,1) \n",
    "                          weight_initializer=glorot_uniform, \n",
    "                          weight_kwargs=init_kwargs)\n",
    "        self.conv2 = conv(21, 10, 257, 98 , stride =(1,2)\n",
    "                          weight_initializer=glorot_uniform, \n",
    "                          weight_kwargs=init_kwargs)\n",
    "        self.conv3 = conv(10, 7, 80, 36 , stride =(16,4)\n",
    "                          weight_initializer=glorot_uniform, \n",
    "                          weight_kwargs=init_kwargs)\n",
    "        self.dense1 = dense(210, ljkjlhl, \n",
    "                            weight_initializer=glorot_uniform, \n",
    "                            weight_kwargs=init_kwargs)\n",
    "        self.dense2 = dense(20, 10, \n",
    "                            weight_initializer=glorot_uniform, \n",
    "                            weight_kwargs=init_kwargs)\n",
    "        self.dense3 = dense(10, 20,\n",
    "                            weight_initializer=glorot_uniform,\n",
    "                            weight_kwargs=init_kwargs)\n",
    "        self.dense4 = dense(20, 250,\n",
    "                            weight_initializer=glorot_uniform,\n",
    "                            weight_kwargs=init_kwargs)\n",
    "        self.dense5 = dense(250, 3145728,\n",
    "                            weight_initializer=glorot_uniform,\n",
    "                            weight_kwargs=init_kwargs)\n",
    "        \n",
    "    def __call__(self,startingpic, endingpic):\n",
    "        '''Forward Pass\n",
    "        \n",
    "        Parameter\n",
    "        ---------\n",
    "        starringpic is a nd.array, mg.Tensor  x.shape(3,1024,1024)\n",
    "        \n",
    "        endingpic is a nd.array, mg.Tensor  x.shape(3,1024,1024)\n",
    "        \n",
    "        \n",
    "        Return\n",
    "        --------\n",
    "        middlepic is a nd.array, mg.Tensor  x.shape(3,1024,1024) #Change for next model\n",
    "        \n",
    "        '''\n",
    "        assert isinstance(startingpic, np.ndarray), \"The starting image is not an ndarray\"\n",
    "        assert startingpic.shape == (3,1024,1024), \"Your starting pic in the foward pass is not a (3,1024,1024)\"\n",
    "        assert isinstance(endingpic, np.ndarray), \"The ending image is not an ndarray\"\n",
    "        assert endingpic.shape == (3,1024,1024), \"Your ending pic in the foward pass is not a (3,1024,1024)\"\n",
    "        #Hstack wont be used because it transposes the matrix as in a=1,2,3 b = 5,6,7 then hstack(a,b) is 1,5\n",
    "        #                                                                                                 2,6\n",
    "        #                                                                                                 3,7\n",
    "        #Input = np.hstack((startingpic,endingpic)) \n",
    "        Input = np.zeroes((3,2048,1024))\n",
    "        Input[:3, :1024, :1024] = startingpic\n",
    "        Input[:3, 1024:, :1024] = endingpic\n",
    "        x = relu(dropout(self.conv1(Input)),.2)\n",
    "        print(f\"The input after the first conv is {x.shape}\")\n",
    "        x = max_pool(x, (2, 2), 2)\n",
    "        print(f\"The input after the first pool is {x.shape}\")\n",
    "        x = relu(dropout(self.conv2(x)),.2)\n",
    "        print(f\"The input after the second conv is {x.shape}\")\n",
    "        x = max_pool(x, (2, 2), 2)\n",
    "        print(f\"The input after the second pool is {x.shape}\")\n",
    "        #x = relu(self.dense1(x.reshape(x.shape[0], -1)))\n",
    "        x = relu (self.dense1(x))\n",
    "        x = relu (self.dense2(x))\n",
    "        x= relu (dropout(self.dense3(x)),.2)\n",
    "        x = relu (self.dense4(x))\n",
    "        x= relu (self.dense5(x))\n",
    "        x=np.reshape(x,(3,1024,1024))\n",
    "\n",
    "        return x\n",
    "   \n",
    "    \n",
    "    @property\n",
    "    def parameters(self):\n",
    "        '''Returns the weights of the model'''\n",
    "        return list(self.conv1.parameters)+list(self.conv2.parameters)+list(self.dense1.parameters)+list(self.dense2.parameters)+list(self.dense3.parameters)+list(self.dense4.parameters)+list(self.dense5.parameters)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'np' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-4661cd47f2d5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mmynn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptimizers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madam\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mAdam\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mModelT\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m   \u001b[1;31m#Might have to change\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0moptimizer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mAdam\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlearning_rate\u001b[0m \u001b[1;33m=\u001b[0m\u001b[1;36m.01\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight_decay\u001b[0m \u001b[1;33m=\u001b[0m\u001b[1;36m.2\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#HYPERPARAMETERS why these values?\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-1-c8d44d26415b>\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m      9\u001b[0m         '''The initial state of the model\n\u001b[0;32m     10\u001b[0m         '''\n\u001b[1;32m---> 11\u001b[1;33m         \u001b[0minit_kwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;34m'gain'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m \u001b[1;31m#MIGHT CHANGE\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'np' is not defined"
     ]
    }
   ],
   "source": [
    "from mynn.optimizers.adam import Adam\n",
    "model = ModelT()   #Might have to change\n",
    "optimizer = Adam(model.parameters, learning_rate =.01, weight_decay =.2) #HYPERPARAMETERS why these values?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.arange(3*1024*1024)\n",
    "x=np.reshape(x,[3,1024,1024])\n",
    "x= CleanData(x)\n",
    "y = np.arange(3*1024*1024)\n",
    "y=np.reshape(y,[3,1024,1024])\n",
    "y= CleanData(y)\n",
    "print(x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "z = model(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
